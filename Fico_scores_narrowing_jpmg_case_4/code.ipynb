{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d62c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6938ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load only required columns\n",
    "df = pd.read_csv('Loan_Data.csv')\n",
    "df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "use_cols = ['fico_score', 'default']\n",
    "dfq = df[use_cols].copy()\n",
    "\n",
    "# Clean numeric\n",
    "dfq['fico_score'] = pd.to_numeric(dfq['fico_score'], errors='coerce')\n",
    "dfq['default']   = pd.to_numeric(dfq['default'], errors='coerce')\n",
    "\n",
    "# Drop missing and non-binary targets\n",
    "dfq = dfq.dropna(subset=['fico_score', 'default'])\n",
    "dfq = dfq[dfq['default'].isin([0,1])]\n",
    "\n",
    "# Basic stats\n",
    "print(\"Count:\", len(dfq))\n",
    "print(\"FICO min/max:\", dfq['fico_score'].min(), dfq['fico_score'].max())\n",
    "print(\"FICO percentiles:\", dfq['fico_score'].quantile([0.01,0.1,0.5,0.9,0.99]).to_dict())\n",
    "print(\"Default rate:\", dfq['default'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdbabc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide number of buckets\n",
    "K = 10  # change if needed\n",
    "\n",
    "# Compute raw quantile edges\n",
    "qs = np.linspace(0, 1, K+1)\n",
    "edges = dfq['fico_score'].quantile(qs).values\n",
    "\n",
    "# Enforce strictly increasing edges by removing duplicates\n",
    "# (can happen if many identical scores)\n",
    "edges_unique = [edges[0]]\n",
    "for v in edges[1:]:\n",
    "    if v > edges_unique[-1]:\n",
    "        edges_unique.append(v)\n",
    "# If we lost edges due to ties, reduce K accordingly\n",
    "K_eff = len(edges_unique) - 1\n",
    "print(f\"Requested K={K}, effective K after tie handling={K_eff}\")\n",
    "boundaries = np.array(edges_unique)\n",
    "\n",
    "print(\"Quantile boundaries:\", boundaries)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# boundaries and K_eff must be defined from Step 2\n",
    "bins = boundaries\n",
    "labels = list(range(1, K_eff+1))  # temporary labels 1..K_eff (low FICO -> low label)\n",
    "\n",
    "# Assign provisional bin indices (0..K_eff-1) using pandas.cut\n",
    "# include_lowest=True ensures the minimum is included\n",
    "bin_idx = pd.cut(dfq['fico_score'], bins=bins, include_lowest=True, right=True, labels=False)\n",
    "\n",
    "# Map to ratings where lower rating = better credit (higher FICO)\n",
    "# Highest bin (largest FICO) should be rating 1\n",
    "rating = (K_eff - bin_idx).astype(int)\n",
    "\n",
    "dfq['rating'] = rating\n",
    "\n",
    "# Quick checks: population and PD per rating\n",
    "by = dfq.groupby('rating').agg(\n",
    "    n=('default','size'),\n",
    "    avg_fico=('fico_score','mean'),\n",
    "    pd_rate=('default','mean')\n",
    ").sort_index()\n",
    "\n",
    "print(by)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da125bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start from per-rating stats\n",
    "stats = dfq.groupby('rating').agg(\n",
    "    n=('default','size'),\n",
    "    k=('default','sum')\n",
    ").sort_index().reset_index()\n",
    "\n",
    "# PAV: enforce non-increasing PD as rating improves (rating 1 best)\n",
    "stats['pd'] = stats['k'] / stats['n']\n",
    "\n",
    "# Convert to lists for merging\n",
    "ratings = stats['rating'].tolist()\n",
    "n = stats['n'].astype(float).tolist()\n",
    "k = stats['k'].astype(float).tolist()\n",
    "pd_list = stats['pd'].tolist()\n",
    "\n",
    "i = 0\n",
    "while i < len(pd_list) - 1:\n",
    "    # pd should be non-decreasing as rating index increases (worse credit has higher PD)\n",
    "    if pd_list[i] > pd_list[i+1]:\n",
    "        # Merge i and i+1\n",
    "        n_merge = n[i] + n[i+1]\n",
    "        k_merge = k[i] + k[i+1]\n",
    "        pd_merge = k_merge / n_merge\n",
    "        # Replace i with merged, remove i+1\n",
    "        n[i] = n_merge; k[i] = k_merge; pd_list[i] = pd_merge\n",
    "        del n[i+1]; del k[i+1]; del pd_list[i+1]; del ratings[i+1]\n",
    "        # Step back one position if possible to re-check monotonicity\n",
    "        if i > 0:\n",
    "            i -= 1\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "# Build mapping from original rating to pooled group index\n",
    "# After pooling, reindex pooled groups to consecutive ratings 1..len(pools)\n",
    "pooled_groups = list(range(1, len(pd_list)+1))\n",
    "rating_map = {old: pooled_groups[idx] for idx, old in enumerate(ratings)}\n",
    "\n",
    "# Apply mapping\n",
    "dfq['rating_pooled'] = dfq['rating'].map(rating_map)\n",
    "\n",
    "# Summarize pooled ratings\n",
    "by_pooled = dfq.groupby('rating_pooled').agg(\n",
    "    n=('default','size'),\n",
    "    avg_fico=('fico_score','mean'),\n",
    "    pd_rate=('default','mean')\n",
    ").sort_index()\n",
    "\n",
    "print(by_pooled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Choose which ratings to finalize: pooled or original\n",
    "use_col = 'rating_pooled' if 'rating_pooled' in dfq.columns else 'rating'\n",
    "\n",
    "diag = dfq.groupby(use_col).agg(\n",
    "    n=('default','size'),\n",
    "    avg_fico=('fico_score','mean'),\n",
    "    pd_rate=('default','mean')\n",
    ").sort_index()\n",
    "print(diag)\n",
    "\n",
    "# Simple checks\n",
    "min_bucket_size = diag['n'].min()\n",
    "is_monotone = (diag['pd_rate'].values == np.sort(diag['pd_rate'].values)).all()\n",
    "print(\"Min bucket size:\", min_bucket_size)\n",
    "print(\"PD monotone non-decreasing with worse rating:\", is_monotone)\n",
    "\n",
    "# Finalize boundaries (bins) and build a rater\n",
    "final_bins = boundaries  # if pooling changed groups, you may recompute explicit cutpoints per pooled rating\n",
    "def rate_fico(fico_value, bins=final_bins):\n",
    "    # Returns rating where 1 = best (highest bin), K = worst (lowest bin)\n",
    "    idx = pd.cut(pd.Series([fico_value]), bins=bins, include_lowest=True, right=True, labels=False).iloc[0]\n",
    "    return int(len(bins)-1 - idx)  # invert so best score -> 1\n",
    "\n",
    "# Example usage:\n",
    "# print(rate_fico(780))\n",
    "# print(rate_fico(620))\n",
    "\n",
    "import json\n",
    "artifact = {'bins': final_bins.tolist(), 'rating_best_is_1': True}\n",
    "with open('fico_rating_map.json','w') as f:\n",
    "    json.dump(artifact, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
