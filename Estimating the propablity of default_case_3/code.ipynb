{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61622de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PD modeling and Expected Loss estimation pipeline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import roc_auc_score , average_precision_score , log_loss ,brier_score_loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "df = pd.read_csv('Loan_Data.csv')\n",
    "df.head()\n",
    "target = 'default'\n",
    "numeric_columns = df.columns.values[1:-1]\n",
    "x = df[numeric_columns].copy()\n",
    "y = df['default'].astype(int).values\n",
    "x_train , x_test , y_train , y_test =train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
    "\n",
    "# 3) Preprocessing for numeric features\n",
    "# SimpleImputer(strategy='median'): fills missing numeric values with median\n",
    "# StandardScaler(): zero-mean, unit-variance scaling, helpful for logistic regression\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 4) ColumnTransformer to apply numeric_transformer to numeric_features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 5) Logistic Regression model\n",
    "# class_weight='balanced' helps when default=1 is rare\n",
    "log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', solver='lbfgs')\n",
    "\n",
    "# 6) Build the full pipeline\n",
    "log_reg_pipeline = Pipeline(steps=[\n",
    "    ('prep', preprocessor),\n",
    "    ('model', log_reg)\n",
    "])\n",
    "\n",
    "# This pipeline supports .fit(X_train, y_train) and .predict_proba(X_valid)\n",
    "\n",
    "\n",
    "# 1) Train the model\n",
    "log_reg_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# 2) Predict probabilities on validation set\n",
    "val_proba = log_reg_pipeline.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# 3) Evaluate\n",
    "roc = roc_auc_score(y_test, val_proba)\n",
    "pr = average_precision_score(y_test, val_proba)\n",
    "ll = log_loss(y_test, val_proba )\n",
    "br = brier_score_loss(y_test, val_proba)\n",
    "\n",
    "print(f\"Validation ROC AUC: {roc:.3f}\")\n",
    "print(f\"Validation PR AUC: {pr:.3f}\")\n",
    "print(f\"Validation Log Loss: {ll:.4f}\")\n",
    "print(f\"Validation Brier Score: {br:.4f}\")\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b0656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree \n",
    "\n",
    "# Create the decision tree with some regularization to avoid overfitting\n",
    "tree_clf = DecisionTreeClassifier(\n",
    "    max_depth=6,           # limit depth\n",
    "    min_samples_leaf=50,   # minimum samples per leaf\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tree_pipeline = Pipeline(steps=[\n",
    "    ('prep', preprocessor),   # reuse the same preprocessor from Step 2\n",
    "    ('model', tree_clf)\n",
    "])\n",
    "\n",
    "# Fit\n",
    "tree_pipeline.fit(x_train, y_train)\n",
    "\n",
    "# Predict probabilities for the positive class (default=1)\n",
    "val_proba_tree = tree_pipeline.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Evaluate\n",
    "roc_t = roc_auc_score(y_test, val_proba_tree)\n",
    "pr_t = average_precision_score(y_test, val_proba_tree)\n",
    "ll_t = log_loss(y_test, val_proba_tree)\n",
    "br_t = brier_score_loss(y_test, val_proba_tree)\n",
    "\n",
    "print(f\"Tree - Validation ROC AUC: {roc_t:.3f}\")\n",
    "print(f\"Tree - Validation PR AUC: {pr_t:.3f}\")\n",
    "print(f\"Tree - Validation Log Loss: {ll_t:.4f}\")\n",
    "print(f\"Tree - Validation Brier Score: {br_t:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defing the fnal loss fucntion \n",
    "\n",
    "\n",
    "def compute_expected_loss(csv_path='Loan_Data.csv', recovery_rate=0.10):\n",
    "    \"\"\"\n",
    "    Trains a simple PD model (logistic regression) on the dataset and returns a DataFrame\n",
    "    with Probability of Default (PD) and Expected Loss (EL) for each row.\n",
    "    EL = PD * (1 - recovery_rate) * loanamtoutstanding\n",
    "    \"\"\"\n",
    "    # 1) Load\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # 2) Standardize column names and choose features/target\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "    target = 'default'\n",
    "    feature_cols = df.columns.values[1:-1]\n",
    "    feature_cols = [c for c in feature_cols if c in df.columns]\n",
    "\n",
    "    # Keep only rows with target\n",
    "    df = df.dropna(subset=[target])\n",
    "\n",
    "    # X/y\n",
    "    X = df[feature_cols].copy()\n",
    "    y = df[target].astype(int).values\n",
    "\n",
    "    # 3) Preprocess + baseline logistic regression\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer, feature_cols)]\n",
    "    )\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=1000, class_weight='balanced', solver='lbfgs')\n",
    "\n",
    "    pipe = Pipeline(steps=[\n",
    "        ('prep', preprocessor),\n",
    "        ('model', log_reg)\n",
    "    ])\n",
    "\n",
    "    # 4) Simple train/validation split and fit\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # 5) Predict PD on the full dataset (or use only validation/test if preferred)\n",
    "    pd_est = pipe.predict_proba(X)[:, 1]\n",
    "\n",
    "    # 6) Compute Expected Loss\n",
    "    lgd = 1.0 - float(recovery_rate)\n",
    "    ead = df['loan_amt_outstanding'].astype(float).fillna(0.0)\n",
    "    el = pd_est * lgd * ead\n",
    "\n",
    "    # 7) Return results with original identifiers if present\n",
    "    out = df.copy()\n",
    "    out['PD'] = pd_est\n",
    "    out['Expected_Loss'] = el\n",
    "    return out[['PD', 'Expected_Loss'] + [c for c in df.columns if c not in ['pd','expected_loss']]]\n",
    "\n",
    "# Example:\n",
    "# results = compute_expected_loss('Loan-Data.csv', recovery_rate=0.10)\n",
    "# print(results.head())\n",
    "compute_expected_loss()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
